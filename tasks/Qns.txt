[1] Explain the different IPC mechanisms available in C++ for inter-process communication
    Pipes (Anonymous and Named Pipes)
    Message Queues
    Shared Memory
In your explanation, provide real-world use cases for each mechanism [Minhaj]

--Inter-Process Communication (IPC) refers to the mechanisms that allow processes to communicate with each other, especially when they are running in a multitasking operating system. IPC is critical for applications that require collaboration between different processes, such as multi-threaded or distributed systems. In C++, IPC can be implemented using several mechanisms, each suited for different use cases. Let's explore and compare the main IPC mechanisms: Pipes, Message Queues, Shared Memory, Semaphores, and Sockets.

1. Pipes (Anonymous and Named Pipes)
Description:

Pipes provide a simple way for processes to communicate through a unidirectional channel. Data written by one process can be read by another process.
Anonymous pipes are typically used for communication between parent and child processes.
Named pipes (FIFOs) allow communication between unrelated processes and persist even after the processes have terminated.
Advantages:

Simple to implement.
No need for explicit memory management in the case of pipes.
Named pipes allow communication between processes without a parent-child relationship.
Limitations:

Unidirectional (for standard pipes), meaning communication is limited to one direction unless two pipes are used.
Pipes have a small buffer size, which can limit throughput.
Not well-suited for large or complex data sharing.
Real-World Use Case:

Communication between a producer process (e.g., a log generator) and a consumer process (e.g., a log analyzer).
Data flows in a simple manner, where one process writes to the pipe and the other reads.
2. Message Queues
Description:

A message queue allows processes to send and receive messages in a queue-like structure. The messages are typically structured and can be received in the order they were sent or according to a priority.
Advantages:

Supports both synchronous and asynchronous communication.
Enables prioritized message delivery (if needed).
Suitable for message-based communication patterns where data is exchanged in discrete chunks.
Limitations:

Message queues can introduce overhead due to queuing mechanisms.
Limited by the system’s message size and number of messages it can handle.
May introduce latency due to queuing.
Real-World Use Case:

Used in systems where different processes need to exchange messages, such as notification systems or task scheduling systems.
For instance, in a distributed application like an online order processing system, different components (order processing, payment processing, shipping) might communicate through message queues.
3. Shared Memory
Description:

Shared memory allows multiple processes to access the same region of memory. This is the fastest IPC method since it avoids the need for kernel intervention once memory is mapped.
Advantages:

Fast: Since memory is shared, processes can communicate with minimal overhead.
Ideal for high-throughput, low-latency applications.
Enables processes to share complex data structures (like arrays, buffers, etc.).
Limitations:

Requires synchronization mechanisms (such as semaphores or mutexes) to avoid race conditions.
Can be complex to manage (e.g., handling data consistency and synchronization).
Access control and security can be tricky, as multiple processes are modifying the same memory.
Real-World Use Case:

Shared memory is used in scenarios where large amounts of data need to be shared quickly, such as in multimedia processing (e.g., video encoding) or real-time data processing.
Example: A video processing application where multiple processes access the same memory region to read frames and write processed frames.

[2] The synchronization mechanisms you would use to prevent race conditions. [Vinayak]

--Race conditions occur when multiple threads access shared data simultaneously, leading to unpredictable results. To prevent race conditions, synchronization mechanisms are needed to ensure that only one thread can access a shared resource at a time.

Mechanisms to Use:
Mutexes (std::mutex): The most basic synchronization primitive to avoid race conditions. A mutex ensures that only one thread can access a critical section of code at any given time. Using std::mutex along with std::lock_guard or std::unique_lock guarantees thread-safe access to shared resources.

std::mutex: A simple lock that prevents multiple threads from accessing a shared resource at the same time.
std::lock_guard: A lock wrapper that automatically locks a mutex when created and unlocks it when it goes out of scope, ensuring no manual unlocking is missed.
std::unique_lock: A more flexible lock that allows manual unlocking and locking, and can also be used with condition variables.
Atomic Operations (std::atomic): For simple types like integers, using atomic operations (via std::atomic) ensures that operations like increment or decrement are performed atomically without the need for locks, making them faster in some cases.

[3] Techniques to manage thread communication and coordination efficiently. [PichuMani]

--Efficient thread communication and coordination are necessary to ensure that threads can work together without unnecessary delays or conflicts.

Condition Variables: These are used to block a thread until a certain condition is met, enabling threads to communicate when certain events occur. std::condition_variable is typically used in combination with a std::mutex to synchronize the threads. For example, in a producer-consumer problem, the producer might wait for an empty slot in the buffer before producing, while the consumer waits for a full buffer before consuming.

Futures and Promises: Used for communication between threads, allowing one thread to send a result to another. A std::promise is used by the producer thread to set a value, and a std::future is used by the consumer thread to retrieve that value.

Thread Join/Detach: After a thread completes its task, it should either be joined using std::thread::join() or detached using std::thread::detach(). Joining ensures that the main thread waits for the worker thread to finish before continuing, while detaching allows the thread to run independently.

[4] Explain the concept of polymorphism and its advantages in object-oriented design. [Minhaj]

--Polymorphism is one of the four fundamental principles of object-oriented programming (OOP), along with encapsulation, inheritance, and abstraction. It refers to the ability of one function, class, or operator to work with different types or classes. Essentially, polymorphism allows the same interface to be used for different underlying forms (data types or class behaviors).

Types of Polymorphism:

Compile-time Polymorphism (also known as static polymorphism): This is achieved through method overloading and operator overloading, where the function or method to be invoked is determined at compile time.
Run-time Polymorphism (also known as dynamic polymorphism): This is achieved through method overriding via virtual functions, where the function to be invoked is determined at runtime.
Advantages of Polymorphism:

Flexibility and Extensibility: Polymorphism allows you to write more flexible and general code. You can treat different objects of different classes in a uniform manner, using a common interface.

Example: A base class Shape with derived classes Circle and Rectangle can have a common function draw(), and each derived class can implement its own version of draw().
Code Reusability: Polymorphism enables you to reuse the same code with different types of objects, reducing redundancy and making the system easier to maintain.

Improved Maintainability: With polymorphism, you can introduce new classes that fit within an existing framework without changing the client code that uses polymorphic behavior.

Decoupling of Code: Polymorphism reduces dependency between objects and functions. Changes in one class or method don’t necessarily affect others, improving the modularity of the code.

[5] Discuss the difference between method overloading and method overriding [Vinayak]

--Method Overloading:

Definition: Method overloading occurs when two or more methods in the same class have the same name but differ in the type, number, or order of parameters. The return type may or may not be different.
Conditions for Overloading:
The method name must be the same.
The parameters must differ in the type, number, or order.
Overloading can happen within the same class or across derived classes.
Usage: Overloading is used to provide multiple ways of performing the same operation depending on the input. For example, you can overload a sum() method to accept either integers or floating-point numbers.
Example: A print() function that takes either an integer or a string as an argument.
Advantages of Overloading:

Improved code readability by using the same function name for similar actions.
Simplifies code by allowing different types of input with the same function name.
Method Overriding:

Definition: Method overriding occurs when a derived class provides a specific implementation of a method that is already defined in its base class. The method signature in the derived class must be the same as in the base class.
Scenario of Overriding:
Overriding allows a child class to modify or extend the functionality of a method inherited from its parent class.
This is typically used to define behavior that is specific to the derived class, while still maintaining a uniform interface.
Conditions for Overriding:

The method in the base class must be virtual (or abstract in the case of an abstract class).
The method signature in the derived class must exactly match the base class method.
Overriding is typically used in inheritance hierarchies to provide specialized behavior in the derived class.
Advantages of Overriding:

Runtime polymorphism: It allows a function call to be resolved at runtime based on the actual object type, rather than the type of the reference or pointer.
Customization: It allows a derived class to provide its specific implementation while still using the same method signature as the base class.

[6] Explain the concept and advantages of smart pointers in C++11 [PichuMani]

--Smart pointers in C++11 are wrappers around raw pointers that automatically manage memory, ensuring proper resource cleanup and preventing memory leaks, double frees, and dangling pointers.

There are three types of smart pointers introduced in C++11:

std::unique_ptr: Represents exclusive ownership of an object. Only one unique_ptr can own a given resource at a time. It automatically deletes the resource when it goes out of scope, preventing memory leaks.
std::shared_ptr: Represents shared ownership. Multiple shared_ptr instances can point to the same resource, and the resource is destroyed when the last shared_ptr pointing to it is destroyed.
std::weak_ptr: A non-owning reference to an object managed by shared_ptr. It prevents circular references that could otherwise cause memory leaks.
